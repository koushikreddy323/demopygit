REFERENCE LINK----https://github.com/Pierian-Data/Complete-Python-3-Bootcamp/blob/master/13-Web-Scraping/00-Guide-to-Web-Scraping.ipynb-----------
------------------http://quotes.toscrape.com/


WEB SCRAPING IS USED TO GET ALL THE DATA FROM A WEBPAGE !
Firstly we need to install bs4,requests,lxml
import requests
import bs4
request=requests.get('https://cricbuzz.com')
request.text---------------------------THIS GETS THE SOURCE CODE OF THE WEBSITE.
HERE TO GET THE CODE IN THE SAME FORMAT AS IT SHOWS IN THE SITE WE HAVE TO GET TO SOUP.
soup= BeautifulSoup(requests.text,'lxml')
soup-----------------------------------THIS GETS INTO THE FORMAT OF THE WEBSITE.
soup.select('title')[0].getText--------HERE IN PLACE OF TITLE WE CAN PLACE WHAT WE NEED LIKE DIV,P,HEAD. HERE THE SOUP WILL BE IN LIST FORMAT SO WE NEED TO GRAB THE 0TH ELEMENT.
---------------------------------------------------------------------------------------------------------
TO GET ALL THE SECTION HEADINGS FROM WIKIPEDIA PAGE  (https://en.wikipedia/wiki/internet')
soup.select('.toctext')
for x in soup.select('.toctext'):
    print(x.next)----------------------FROM THIS WE WILL GET THE LIST OF ALL THE SECTIONS IN THAT WIKI PAGE
---------------------------------------------------------------------------------------------------------
TO READ THE IMAGE FROM WIKIPEDIA AND DOWNLOAD ON COMPUTER

res=requests.get('https://en.wikipedia.org/wiki/Royal_Challengers_Bangalore')
soup=bs4.BeautifulSoup(res.text,'lxml')
(soup.select('.image')[4])------------THIS IS THE CLASS NAME FROM THE WEBSITE AND BELOW IS THE LINK OF IMAGE SRC.
c=requests.get('https://upload.wikimedia.org/wikipedia/commons/6/66/Kit_right_arm_yellowborder.png')
f=open('rcb2.png','wb')
f.write(c.content)
f.close()
---------------------------------------------------------------------------------------------------------
TO GET ALL THE BOOKS WITH 2 STAR RATING
import requests
import bs4
base_url='http://books.toscrape.com/catalogue/page-{}.html'
res=requests.get(base_url.format(1))
soup=bs4.BeautifulSoup(res.text,'lxml')
products=soup.select('.product_pod')
example=products[0]
example.select('.star-rating.Three')  #place dot instead of spaces
two_star_rating_books=[]
for x in range(1,51):
    scraped_url=base_url.format(x)
    res=requests.get(scraped_url)
    soup=bs4.BeautifulSoup(res.text,'lxml')
    books=soup.select('.product_pod')
    for book in books:
        if len(book.select('.star-rating.Two'))!=0:
            book_title=book.select('a')[1]['title']
            two_star_rating_books.append(book_title)
i=0
for x in two_star_rating_books:
    print(i,'.',x)
    i+=1
---------------------------------------------------------------------------------------------------------
TO GET ALL THE NAMES OF AUTHORS IN A WEBPAGE

res=requests.get('http://quotes.toscrape.com')
soup=bs4.BeautifulSoup(res.text,'lxml')
x=soup.select('.author')
authors=set()
for name in soup.select('.author'):
    authors.add(name.text)
print(authors)
---------------------------------------------------------------------------------------------------------
TO GET ALL THE QUOTES IN A PAGE

res=requests.get('http://quotes.toscrape.com/page/2')
soup=bs4.BeautifulSoup(res.text,'lxml')
x=soup.select('.text')
quotes=[]
for quote in soup.select('.text'):
    quotes.append(quote.text)
i=1
for x in quotes:
    print(i,'.',x)
    i+=1
---------------------------------------------------------------------------------------------------------
TO GET TOP 10 TAGS IN WEBSITE

res=requests.get('http://quotes.toscrape.com/page/1')
soup=bs4.BeautifulSoup(res.text,'lxml')
x=soup.select('.tag-item')

for v in soup.select('.tag-item'):
    print(v.text)
--------------------------------------------------------------------------------------------------------
TO GET ALL THE UNIQUE AUTHORS IN ALL PAGES OF A WEBSITE

base_url='http://quotes.toscrape.com/page/{}'
authors=set()
for page in range(1,11):
    derived_url=base_url.format(page)
    res=requests.get(derived_url)
    soup=bs4.BeautifulSoup(res.text,'lxml')
    x=soup.select('.author')
    for name in x:
        authors.add(name.text)
print(authors)
---------------------------------------------------------------------------------------------------------